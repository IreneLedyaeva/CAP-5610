{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "problem_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IreneLedyaeva/CAP-5610/blob/master/HW2/problem_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pwfDXmfJ_zK3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the CIFAR10 data set"
      ]
    },
    {
      "metadata": {
        "id": "JhDk_-QE_2Ns",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(non_test_images, non_test_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVOZsyMM18jB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Splitting non-test data into training and validation"
      ]
    },
    {
      "metadata": {
        "id": "j2pjCIjQ2DQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8809e095-ff29-4f73-8a9f-368a7d133c6d"
      },
      "cell_type": "code",
      "source": [
        "num_validation_samples = int(non_test_images.shape[0] * 0.2)\n",
        "\n",
        "train_images = non_test_images[num_validation_samples:] \n",
        "validation_images = non_test_images[:num_validation_samples]\n",
        "\n",
        "train_labels = non_test_labels[num_validation_samples:] \n",
        "validation_labels = non_test_labels[:num_validation_samples]\n",
        "\n",
        "print('total training images:', train_images.shape[0])\n",
        "print('total validation images:', validation_images.shape[0])\n",
        "print('total test images:', test_images.shape[0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training images: 40000\n",
            "total validation images: 10000\n",
            "total test images: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7dHHcp5USgOD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Encoding the labels"
      ]
    },
    {
      "metadata": {
        "id": "Ecf4mka-SusC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "class_names = ['airplan', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "validation_labels = to_categorical(validation_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "90zmcK2hhyWQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the data"
      ]
    },
    {
      "metadata": {
        "id": "eNeeHK0Qh1r9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype('float32') / 255.0\n",
        "validation_images = validation_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nx40fYO57VQs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Adding data augmentation\n",
        "Validation and test data should not be augmented"
      ]
    },
    {
      "metadata": {
        "id": "PiRs1w0t7ZmG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Training images\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "datagen.fit(train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tOK5_ixvAzcR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Building the model and adding dropout"
      ]
    },
    {
      "metadata": {
        "id": "1giH-P1NI9pl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Model[1]\n",
        "model_1 = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "# Model[2]\n",
        "# Model[3]\n",
        "# Model[4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S6wmyqtMJW6I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "metadata": {
        "id": "gJjJAvwDJf8P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W9CBde1GJpe-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ]
    },
    {
      "metadata": {
        "id": "B--p3OsrJvTt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#history = model_1.fit_generator(datagen.flow(train_images, train_labels, batch_size=32), epochs=30, validation_data=(validation_images, validation_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iLytHSp_ds6C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking overfitting"
      ]
    },
    {
      "metadata": {
        "id": "K6t234ovdv3s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}